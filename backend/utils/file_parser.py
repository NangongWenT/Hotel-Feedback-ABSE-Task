import csv
import io
import traceback


def parse_uploaded_file(file_storage):
    """
    [Ultimate Enhanced Version] Parse Uploaded Files
    Features:
    1. Automatically detects CSV delimiter (comma ',' or semicolon ';') <-- Fixed core issue
    2. Automatically handles BOM headers and multiple encoding formats
    3. Brute-force fuzzy matching for column names
    4. Enhanced error handling and detailed logging
    """
    filename = file_storage.filename.lower()
    print(f"ğŸ“„ å¼€å§‹è§£ææ–‡ä»¶: {file_storage.filename}")

    # 1. Read binary data
    try:
        stream = file_storage.read()
        if not stream:
            print("âŒ ä¸Šä¼ æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•è§£æ")
            return []
        print(f"ğŸ“Š è¯»å–åˆ°æ–‡ä»¶å¤§å°: {len(stream)} å­—èŠ‚")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return []

    # 2. Try to decode content - optimized encoding handling
    content = None
    encoding_used = 'utf-8'
    
    # Try multiple common encodings
    encodings = [
        ('utf-8-sig', 'UTF-8 (å¸¦BOM)'),
        ('gbk', 'GBK'),
        ('gb2312', 'GB2312'),
        ('latin-1', 'Latin-1'),
        ('utf-16', 'UTF-16')
    ]
    
    for encoding, desc in encodings:
        try:
            content = stream.decode(encoding)
            encoding_used = encoding
            print(f"âœ… æˆåŠŸä½¿ç”¨ç¼–ç : {desc} ({encoding})")
            break
        except UnicodeDecodeError:
            print(f"ğŸ”„ å°è¯•ç¼–ç  {desc} å¤±è´¥ï¼Œç»§ç»­å°è¯•")
        except LookupError:
            print(f"âš ï¸ ä¸æ”¯æŒçš„ç¼–ç : {encoding}")
    
    # Fallback solution
    if content is None:
        try:
            print("âš ï¸ æ‰€æœ‰æ ‡å‡†ç¼–ç å°è¯•å¤±è´¥ï¼Œä½¿ç”¨å¿½ç•¥é”™è¯¯æ¨¡å¼")
            content = stream.decode('utf-8', errors='replace')
            encoding_used = 'utf-8 (with replacement)'
        except:
            print("âŒ æ–‡ä»¶ç¼–ç æ— æ³•è¯†åˆ«ï¼Œæ— æ³•ç»§ç»­è§£æ")
            return []

    # 3. Convert to file object
    f = io.StringIO(content)

    # 4. [Key Step] Automatically detect delimiter - optimized logic
    delimiter = ','  
    try:
    
        sample = content[:2048]
        
        # Alternative 1: Use csv.Sniffer
        try:
            dialect = csv.Sniffer().sniff(sample, delimiters=[',', ';', '\t', '|'])
            delimiter = dialect.delimiter
            print(f"ğŸ” csv.Sniffer æ£€æµ‹åˆ°åˆ†éš”ç¬¦: '{delimiter}'")
        except Exception as e:
            print(f"âš ï¸ csv.Sniffer å¤±è´¥: {str(e)}ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•")
            
            # Alternative 2: Count occurrences of possible delimiters in first line
            first_line = sample.split('\n')[0] if '\n' in sample else sample
            possible_delimiters = [';', ',', '\t', '|']
            max_count = 0
            
            for d in possible_delimiters:
                count = first_line.count(d)
                if count > max_count:
                    max_count = count
                    delimiter = d
            
            if max_count > 0:
                print(f"âœ… å¤‡ç”¨æ–¹æ³•æ£€æµ‹åˆ°åˆ†éš”ç¬¦: '{delimiter}' (å‡ºç° {max_count} æ¬¡)")
            else:
                print("âš ï¸ æ— æ³•è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦ï¼Œé»˜è®¤ä½¿ç”¨é€—å·")
    except Exception as e:
        print(f"âŒ åˆ†éš”ç¬¦æ£€æµ‹å¤±è´¥: {str(e)}ï¼Œé»˜è®¤ä½¿ç”¨é€—å·")

    try:
      
        f.seek(0)
        reader = csv.reader(f, delimiter=delimiter)

      
        try:
            headers = next(reader)
          
            headers = [h.strip().strip('"').strip("'") for h in headers]
            print(f"ğŸ” è¯»å–åˆ°è¡¨å¤´: {headers} (å…± {len(headers)} åˆ—)")
        except StopIteration:
            print("âŒ æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è¯»å–è¡¨å¤´")
            return []
        except Exception as e:
            print(f"âŒ è¯»å–è¡¨å¤´å¤±è´¥: {str(e)}")
            return []

        # 5. Intelligently find text column index - enhanced matching logic
        clean_headers = [h.strip().lower() for h in headers]
        target_index = -1
        possible_keys = ['text', 'review', 'content', 'comment', 'body', 'è¯„è®º', 'å†…å®¹', 'åé¦ˆ', 'description']

        # Try exact matching and contains matching
        for i, header in enumerate(clean_headers):
            # Exact match
            if header in possible_keys:
                target_index = i
                print(f"âœ… ç²¾ç¡®å‘½ä¸­åˆ—å: '{headers[i]}' (ç´¢å¼•: {i})")
                break
        
        # If no exact match, try contains matching
        if target_index == -1:
            for i, header in enumerate(clean_headers):
                if any(key in header for key in possible_keys):
                    target_index = i
                    print(f"âœ… æ¨¡ç³Šå‘½ä¸­åˆ—å: '{headers[i]}' (ç´¢å¼•: {i})")
                    break

        # Fallback: If no keywords found, guess based on column count and common patterns
        if target_index == -1:
            if len(headers) == 1:
                target_index = 0
                print("âš ï¸ ä»…æ‰¾åˆ°ä¸€åˆ—ï¼Œé»˜è®¤ä½¿ç”¨è¯¥åˆ—ä½œä¸ºæ–‡æœ¬åˆ—")
            else:
                print(f"âŒ æ— æ³•è¯†åˆ«æ–‡æœ¬åˆ—ã€‚è¯·ç¡®ä¿CSVåŒ…å«ä»¥ä¸‹åˆ—åä¹‹ä¸€: {', '.join(possible_keys)}")
                print(f"   å®é™…è¡¨å¤´: {', '.join(headers)}")
                return []

        # 6. Extract data - enhanced error handling and data cleaning
        results = []
        empty_rows = 0
        invalid_rows = 0
        
        for row_idx, row in enumerate(reader):
            try:
                # Skip empty rows
                if not row or all(not cell.strip() for cell in row):
                    empty_rows += 1
                    continue

                # Check if index is valid
                if len(row) <= target_index:
                    print(f"âš ï¸ è¡Œ {row_idx + 2} åˆ—æ•°ä¸è¶³ï¼Œè·³è¿‡è¯¥è¡Œ")
                    invalid_rows += 1
                    continue

                # Get and clean text
                val = row[target_index].strip()
                # Filter invalid content
                if val and len(val) > 1 and val.lower() not in ['nan', 'none', 'null', 'n/a']:
                    results.append({'text': val})
                else:
                    invalid_rows += 1
            except Exception as e:
                print(f"âŒ å¤„ç†ç¬¬ {row_idx + 2} è¡Œæ—¶å‡ºé”™: {str(e)}")
                invalid_rows += 1
                continue

        # Output statistics
        total_rows = row_idx + 1 if 'row_idx' in locals() else 0
        print(f"ğŸ“Š è§£æç»Ÿè®¡: æ€»è¡Œæ•°={total_rows}, æœ‰æ•ˆæ•°æ®={len(results)}, ç©ºè¡Œ={empty_rows}, æ— æ•ˆè¡Œ={invalid_rows}")
        
        if not results:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹å’Œåˆ—åæ˜¯å¦æ­£ç¡®")
            return []
            
        print(f"âœ… è§£ææˆåŠŸï¼Œå…± {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        return results

    except Exception as e:
        print(f"âŒ è§£æè¿‡ç¨‹å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
        print("ğŸ“‹ è¯¦ç»†é”™è¯¯æ ˆ:")
        traceback.print_exc()
        return []
    finally:
        try:
            file_storage.seek(0)  # Reset file pointer
            print("ğŸ”„ æ–‡ä»¶æŒ‡é’ˆå·²é‡ç½®")
        except:
            print("âš ï¸ é‡ç½®æ–‡ä»¶æŒ‡é’ˆå¤±è´¥")